{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from recbole.quick_start import run_recbole, load_data_and_model\n",
    "from recbole.data import Interaction\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:45    INFO  ['/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py', '--f=/data/ephemeral/home/.local/share/jupyter/runtime/kernel-v35d0b846ea6a4bfeee03f827ae4f77c16df919433.json']\n",
      "27 Nov 02:45    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../data/train/train_ratings\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'item': ['item_id', 'title', 'year', 'genre', 'director', 'writer']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "selected_features = ['genre']\n",
      "pooling_mode = sum\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "27 Nov 02:45    INFO  train_ratings\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'title', 'year', 'genre', 'director', 'writer']\n",
      "27 Nov 02:47    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "27 Nov 02:47    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "27 Nov 02:47    INFO  GRU4RecF(\n",
      "  (item_embedding): Embedding(6808, 64, padding_idx=0)\n",
      "  (feature_embed_layer): FeatureSeqEmbLayer(\n",
      "    (token_embedding_table): ModuleDict()\n",
      "    (float_embedding_table): ModuleDict()\n",
      "    (token_seq_embedding_table): ModuleDict(\n",
      "      (item): ModuleList(\n",
      "        (0): Embedding(760, 64)\n",
      "      )\n",
      "    )\n",
      "    (float_seq_embedding_table): ModuleDict(\n",
      "      (item): ModuleList()\n",
      "    )\n",
      "  )\n",
      "  (item_gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (feature_gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense_layer): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 648256\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:998: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "27 Nov 02:47    INFO  FLOPs: 8288064.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1421081a9749f0911d0ffdbcd8aa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                         | 0/2471 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:49    INFO  epoch 0 training [time: 105.24s, train loss: 17203.4281]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e29379d904d2d8dcbdfcd36f2c208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mEvaluate   \u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:49    INFO  epoch 0 evaluating [time: 0.45s, valid_score: 0.028900]\n",
      "27 Nov 02:49    INFO  valid result: \n",
      "recall@10 : 0.0877    mrr@10 : 0.0289    ndcg@10 : 0.0425    hit@10 : 0.0877    precision@10 : 0.0088\n",
      "27 Nov 02:49    INFO  Saving current: saved/GRU4RecF-Nov-27-2024_02-47-31.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0a997a035848689e2cbaeb09ff4c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mTrain     1\u001b[0m:   0%|                                                         | 0/2471 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:51    INFO  epoch 1 training [time: 106.89s, train loss: 15931.6819]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d03ba3313ac46c1a9230b1c6fa4d2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mEvaluate   \u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:51    INFO  epoch 1 evaluating [time: 0.46s, valid_score: 0.036500]\n",
      "27 Nov 02:51    INFO  valid result: \n",
      "recall@10 : 0.1069    mrr@10 : 0.0365    ndcg@10 : 0.0527    hit@10 : 0.1069    precision@10 : 0.0107\n",
      "27 Nov 02:51    INFO  Saving current: saved/GRU4RecF-Nov-27-2024_02-47-31.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5675588f9bff439bb74695eac3114420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mTrain     2\u001b[0m:   0%|                                                         | 0/2471 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:53    INFO  epoch 2 training [time: 105.78s, train loss: 15583.1729]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084d410d9740477197cd7eb98bc95b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mEvaluate   \u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:53    INFO  epoch 2 evaluating [time: 0.41s, valid_score: 0.041800]\n",
      "27 Nov 02:53    INFO  valid result: \n",
      "recall@10 : 0.1186    mrr@10 : 0.0418    ndcg@10 : 0.0595    hit@10 : 0.1186    precision@10 : 0.0119\n",
      "27 Nov 02:53    INFO  Saving current: saved/GRU4RecF-Nov-27-2024_02-47-31.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773a58d4749240e9a2661066c5715761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mTrain     3\u001b[0m:   0%|                                                         | 0/2471 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:55    INFO  epoch 3 training [time: 106.53s, train loss: 15385.9997]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dae298ae5874e87844ce4ee6112ebfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mEvaluate   \u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 02:55    INFO  epoch 3 evaluating [time: 0.40s, valid_score: 0.046000]\n",
      "27 Nov 02:55    INFO  valid result: \n",
      "recall@10 : 0.1247    mrr@10 : 0.046    ndcg@10 : 0.0642    hit@10 : 0.1247    precision@10 : 0.0125\n",
      "27 Nov 02:55    INFO  Saving current: saved/GRU4RecF-Nov-27-2024_02-47-31.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4acd61c02d54f288c5e14ad63f25f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mTrain     4\u001b[0m:   0%|                                                         | 0/2471 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_recbole(config_file_list=['recbole_config_gru4rec.yaml'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Nov 01:38    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ../data/train/train_ratings\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 10\n",
      "train_batch_size = 256\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'sample_num': 5, 'distribution': 'uniform', 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['mrr', 'recall', 'precision']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 256\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id'], 'item': ['item_id', 'title', 'year', 'genre', 'director', 'writer']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "attention_size = 16\n",
      "n_layers = 3\n",
      "num_heads = 2\n",
      "dropout_probs = [0.2, 0.2, 0.2]\n",
      "mlp_hidden_size = [128, 128]\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "ITEM_FEATURES = ['title', 'year', 'genre', 'director', 'writer']\n",
      "MULTI_VALUE_FIELDS = ['genre', 'director', 'writer']\n",
      "loss_type = BPR\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/opt/conda/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "27 Nov 01:38    INFO  train_ratings\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user_id', 'item_id', 'title', 'year', 'genre', 'director', 'writer']\n",
      "27 Nov 01:38    INFO  [Training]: train_batch_size = [256] train_neg_sample_args: [{'uniform': 1, 'sample_num': 5, 'distribution': 'uniform', 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "27 Nov 01:38    INFO  [Evaluation]: eval_batch_size = [256] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "# model, dataset 불러오기\n",
    "model_path = 'saved/AutoInt-Nov-26-2024_02-45-52.pth'\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(model_path)\n",
    "    \n",
    "# device 설정\n",
    "device = config.final_config_dict['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1df33c915bb4b49b05445af7891b731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['user_id', 'item_id']\n",
      "[]\n",
      "['title', 'genre', 'director', 'writer']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'item_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m interaction \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# user item별 score 예측\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m score \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, item_len)\n\u001b[1;32m     47\u001b[0m rating_pred \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/recbole/model/context_aware_recommender/autoint.py:120\u001b[0m, in \u001b[0;36mAutoInt.predict\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, interaction):\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/recbole/model/context_aware_recommender/autoint.py:106\u001b[0m, in \u001b[0;36mAutoInt.forward\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, interaction):\n\u001b[0;32m--> 106\u001b[0m     autoint_all_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_embed_input_fields\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteraction\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, num_field, embed_dim]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_order_linear(interaction) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoint_layer(\n\u001b[1;32m    110\u001b[0m         autoint_all_embeddings\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/recbole/model/abstract_recommender.py:535\u001b[0m, in \u001b[0;36mContextRecommender.concat_embed_input_fields\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat_embed_input_fields\u001b[39m(\u001b[38;5;28mself\u001b[39m, interaction):\n\u001b[0;32m--> 535\u001b[0m     sparse_embedding, dense_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_input_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse_embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/recbole/model/abstract_recommender.py:590\u001b[0m, in \u001b[0;36mContextRecommender.embed_input_fields\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m    588\u001b[0m token_fields \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_field_names:\n\u001b[0;32m--> 590\u001b[0m     token_fields\u001b[38;5;241m.\u001b[39mappend(\u001b[43minteraction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token_fields) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    592\u001b[0m     token_fields \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    593\u001b[0m         token_fields, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    594\u001b[0m     )  \u001b[38;5;66;03m# [batch_size, num_token_field, 2]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/recbole/data/interaction.py:135\u001b[0m, in \u001b[0;36mInteraction.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteraction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, (np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor)):\n\u001b[1;32m    137\u001b[0m         index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'item_id'"
     ]
    }
   ],
   "source": [
    "self = config\n",
    "\n",
    "recall_n = 10\n",
    "if type(recall_n) == list:\n",
    "    recall_n = recall_n[0]\n",
    "\n",
    "# device 설정\n",
    "device = config.final_config_dict['device']\n",
    "\n",
    "# user, item id -> token 변환 array\n",
    "user_id = self['USER_ID_FIELD']\n",
    "item_id = self['ITEM_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "item_id2token = dataset.field2id_token[item_id]\n",
    "\n",
    "# user id list\n",
    "all_user_list = torch.arange(1, len(user_id2token)).view(-1, 128)\n",
    "\n",
    "# user, item 길이\n",
    "# user_len = len(user_id2token)\n",
    "item_len = len(item_id2token)\n",
    "\n",
    "# user-item sparse matrix\n",
    "matrix = dataset.inter_matrix(form='csr')\n",
    "\n",
    "# user id, predict item id 저장 변수\n",
    "pred_list = None\n",
    "user_list = None\n",
    "\n",
    "# model 평가모드 전환\n",
    "model.eval()\n",
    "\n",
    "# progress bar 설정\n",
    "tbar = tqdm_notebook(all_user_list)\n",
    "\n",
    "for data in tbar:\n",
    "    # interaction 생성\n",
    "    interaction = dict()\n",
    "    interaction = Interaction(interaction)\n",
    "    interaction[user_id] = data\n",
    "    interaction = interaction.to(device)\n",
    "\n",
    "    # user item별 score 예측\n",
    "    score = model.predict(interaction)\n",
    "    score = score.view(-1, item_len)\n",
    "\n",
    "    rating_pred = score.cpu().data.numpy().copy()\n",
    "\n",
    "    user_index = data.numpy()\n",
    "\n",
    "    idx = matrix[user_index].toarray() > 0\n",
    "\n",
    "    rating_pred[idx] = -np.inf\n",
    "    rating_pred[:, 0] = -np.inf\n",
    "    ind = np.argpartition(rating_pred, -recall_n)[:, -recall_n:]\n",
    "\n",
    "    arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], ind]\n",
    "\n",
    "    arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "\n",
    "    batch_pred_list = ind[\n",
    "        np.arange(len(rating_pred))[:, None], arr_ind_argsort\n",
    "    ]\n",
    "\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        user_list = user_index\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        user_list = np.append(\n",
    "            user_list, user_index, axis=0\n",
    "        )\n",
    "\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    for item in pred:\n",
    "        result.append((int(user_id2token[user]), int(item_id2token[item])))\n",
    "\n",
    "# 데이터 저장\n",
    "dataframe = pd.DataFrame(result, columns=[\"user\", \"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('../data/eval/recbole_gru4recf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
