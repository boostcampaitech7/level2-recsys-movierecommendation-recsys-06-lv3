{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from recbole.quick_start import run_recbole, load_data_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# # path 설정\n",
    "# sys.path.append((os.path.abspath(\"\")))\n",
    "# print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Nov 10:50    INFO  ['d:\\\\Program\\\\Dev\\\\ANACONDA\\\\envs\\\\movie\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '--f=c:\\\\Users\\\\shgkd\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3e2a25bc3dd1142fffa4339bd5d4d86411ea1daf8.json']\n",
      "23 Nov 10:50    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./data/train\\train_ratings\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.15, 0.05]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['mrr', 'recall', 'precision']\n",
      "topk = [10]\n",
      "valid_metric = recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "reg_weight = 500\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.TRADITIONAL\n",
      "mode = full\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "d:\\Program\\Dev\\ANACONDA\\envs\\movie\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "23 Nov 10:50    INFO  train_ratings\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "23 Nov 10:50    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "23 Nov 10:50    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.15, 0.05]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "23 Nov 10:54    INFO  EASE()\n",
      "Trainable parameters: 1\n",
      "23 Nov 10:54    INFO  FLOPs: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd0435d0bfe4c3599ada93c9ad7fbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                         | 0/2029 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\Dev\\ANACONDA\\envs\\movie\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "23 Nov 10:54    INFO  epoch 0 training [time: 5.29s, train loss: 0.0000]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab4e4f5ca14c3ab1b15f533ae4307e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mEvaluate   \u001b[0m:   0%|                                                        | 0/31360 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Nov 10:55    INFO  epoch 0 evaluating [time: 43.62s, valid_score: 0.166300]\n",
      "23 Nov 10:55    INFO  valid result: \n",
      "mrr@10 : 0.622    recall@10 : 0.1663    precision@10 : 0.3115\n",
      "23 Nov 10:55    INFO  Saving current: saved\\EASE-Nov-23-2024_10-54-23.pth\n",
      "d:\\Program\\Dev\\ANACONDA\\envs\\movie\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "23 Nov 10:55    INFO  Loading model structure and parameters from saved\\EASE-Nov-23-2024_10-54-23.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9fdfbce8cd464ca4450aeaa4c961c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "\u001b[1;35mEvaluate   \u001b[0m:   0%|                                                        | 0/31360 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Nov 10:56    INFO  The running environment of this training is as follows:\n",
      "+-------------+----------------+\n",
      "| Environment |     Usage      |\n",
      "+=============+================+\n",
      "| CPU         |     2.10 %     |\n",
      "+-------------+----------------+\n",
      "| GPU         | 0.00 G/6.00 G  |\n",
      "+-------------+----------------+\n",
      "| Memory      | 2.29 G/31.67 G |\n",
      "+-------------+----------------+\n",
      "23 Nov 10:56    INFO  best valid : OrderedDict([('mrr@10', 0.622), ('recall@10', 0.1663), ('precision@10', 0.3115)])\n",
      "23 Nov 10:56    INFO  test result: OrderedDict([('mrr@10', 0.3999), ('recall@10', 0.2048), ('precision@10', 0.1351)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_valid_score': 0.1663,\n",
       " 'valid_score_bigger': True,\n",
       " 'best_valid_result': OrderedDict([('mrr@10', 0.622),\n",
       "              ('recall@10', 0.1663),\n",
       "              ('precision@10', 0.3115)]),\n",
       " 'test_result': OrderedDict([('mrr@10', 0.3999),\n",
       "              ('recall@10', 0.2048),\n",
       "              ('precision@10', 0.1351)])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_dict = {\n",
    "    'train_neg_sample_args': None,  # 암시적 피드백 데이터를 위한 설정\n",
    "    'mode': 'full',\n",
    "}\n",
    "run_recbole(config_file_list=['recbole_ease_1.yaml'], config_dict=parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\Dev\\ANACONDA\\envs\\movie\\lib\\site-packages\\recbole\\quick_start\\quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_file)\n",
      "26 Nov 14:46    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./data/train\\train_ratings\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.15, 0.05]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['mrr', 'recall', 'precision']\n",
      "topk = [10]\n",
      "valid_metric = recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "reg_weight = 500\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.TRADITIONAL\n",
      "mode = full\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "d:\\Program\\Dev\\ANACONDA\\envs\\movie\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "26 Nov 14:46    INFO  train_ratings\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "26 Nov 14:46    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "26 Nov 14:46    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.15, 0.05]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "# model, dataset 불러오기\n",
    "model_path = './saved/EASE-Nov-23-2024_10-54-23.pth'\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(model_path)\n",
    "    \n",
    "# device 설정\n",
    "device = config.final_config_dict['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, item id -> token 변환 array\n",
    "user_id2token = dataset.field2id_token['user_id']\n",
    "item_id2token = dataset.field2id_token['item_id']\n",
    "    \n",
    "# user-item sparse matrix\n",
    "matrix = dataset.inter_matrix(form='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user id, predict item id, score 저장 변수 \n",
    "pred_list = None\n",
    "user_list = None\n",
    "score_list = None\n",
    "\n",
    "model.eval()\n",
    "for data in test_data:\n",
    "    interaction = data[0].to(device)\n",
    "    score = model.full_sort_predict(interaction)\n",
    "    \n",
    "    rating_pred = score.cpu().data.numpy().copy().flatten()  # 1차원 배열로 변환\n",
    "    user_id = interaction['user_id'].cpu().item()  # 스칼라 값으로 변환\n",
    "    \n",
    "    # 사용자가 상호작용한 아이템 인덱스를 가져옵니다\n",
    "    interacted_indices = matrix[user_id].indices\n",
    "    \n",
    "    # 상호작용한 아이템의 점수를 0으로 설정합니다\n",
    "    rating_pred[interacted_indices] = 0\n",
    "    \n",
    "    # 상위 10개 아이템 인덱스 추출\n",
    "    ind = np.argpartition(rating_pred, -20)[-20:]\n",
    "    arr_ind = rating_pred[ind]\n",
    "    \n",
    "    # 추출된 값들을 내림차순으로 정렬하기 위한 인덱스를 얻음\n",
    "    arr_ind_argsort = np.argsort(arr_ind)[::-1]\n",
    "    \n",
    "    # 실제 값들을 정렬된 순서대로 인덱스 배열에 적용\n",
    "    batch_pred_list = ind[arr_ind_argsort]\n",
    "    batch_score_list = arr_ind[arr_ind_argsort]\n",
    "    \n",
    "    # 예측값 저장\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        score_list = batch_score_list\n",
    "        # batch_pred_list 길이만큼 user_id를 반복\n",
    "        user_list = np.repeat(user_id, len(batch_pred_list))\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        score_list = np.append(score_list, batch_score_list, axis=0)\n",
    "        # batch_pred_list 길이만큼 user_id를 반복하여 추가\n",
    "        user_list = np.append(user_list, np.repeat(user_id, len(batch_pred_list)), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('11', '4886', 0.8268838),\n",
       " ('11', '4370', 0.7548243),\n",
       " ('11', '8961', 0.7517703),\n",
       " ('11', '40815', 0.69971085),\n",
       " ('11', '47', 0.54835236),\n",
       " ('11', '3996', 0.51813924),\n",
       " ('11', '1704', 0.51013464),\n",
       " ('11', '32587', 0.4920214),\n",
       " ('11', '1127', 0.47097677),\n",
       " ('11', '7373', 0.4667867),\n",
       " ('11', '8360', 0.45052454),\n",
       " ('11', '3081', 0.44645295),\n",
       " ('11', '2', 0.44508183),\n",
       " ('11', '7438', 0.43942633),\n",
       " ('11', '2174', 0.43931624),\n",
       " ('11', '37386', 0.42387974),\n",
       " ('11', '590', 0.42279437),\n",
       " ('11', '1206', 0.4143572),\n",
       " ('11', '37729', 0.40597358),\n",
       " ('11', '1682', 0.39908507),\n",
       " ('14', '919', 0.53935236),\n",
       " ('14', '1223', 0.4934494),\n",
       " ('14', '1035', 0.44524604),\n",
       " ('14', '1907', 0.43798834),\n",
       " ('14', '6539', 0.43737197),\n",
       " ('14', '1198', 0.4330997),\n",
       " ('14', '1028', 0.4219346),\n",
       " ('14', '2011', 0.41975918),\n",
       " ('14', '7147', 0.40701962),\n",
       " ('14', '5816', 0.4038603),\n",
       " ('14', '1073', 0.39745927),\n",
       " ('14', '4016', 0.3853792),\n",
       " ('14', '8368', 0.37522268),\n",
       " ('14', '4857', 0.36862877),\n",
       " ('14', '914', 0.36260253),\n",
       " ('14', '2096', 0.3621986),\n",
       " ('14', '2398', 0.3577361),\n",
       " ('14', '2762', 0.35619694),\n",
       " ('14', '34', 0.35446262),\n",
       " ('14', '7361', 0.34213066),\n",
       " ('18', '2324', 0.45807517),\n",
       " ('18', '1193', 0.44850802),\n",
       " ('18', '5995', 0.44781768),\n",
       " ('18', '296', 0.3911963),\n",
       " ('18', '4235', 0.35340655),\n",
       " ('18', '46578', 0.34921476),\n",
       " ('18', '50', 0.3199211),\n",
       " ('18', '8873', 0.3046358),\n",
       " ('18', '2692', 0.2939494),\n",
       " ('18', '4226', 0.28142473),\n",
       " ('18', '63082', 0.25886023),\n",
       " ('18', '46723', 0.25344837),\n",
       " ('18', '2571', 0.2520586),\n",
       " ('18', '1233', 0.22956094),\n",
       " ('18', '58303', 0.22026864),\n",
       " ('18', '590', 0.2189651),\n",
       " ('18', '1203', 0.20790139),\n",
       " ('18', '2019', 0.2060339),\n",
       " ('18', '1213', 0.20300302),\n",
       " ('18', '41997', 0.20025086),\n",
       " ('25', '1270', 0.6918913),\n",
       " ('25', '7153', 0.67389524),\n",
       " ('25', '47', 0.55753547),\n",
       " ('25', '1', 0.501066),\n",
       " ('25', '1073', 0.49912754),\n",
       " ('25', '2762', 0.485177),\n",
       " ('25', '2291', 0.44562396),\n",
       " ('25', '1923', 0.41441566),\n",
       " ('25', '608', 0.41135845),\n",
       " ('25', '2329', 0.40551814),\n",
       " ('25', '2997', 0.4045134),\n",
       " ('25', '1527', 0.39830577),\n",
       " ('25', '1206', 0.38890964),\n",
       " ('25', '1221', 0.38336158),\n",
       " ('25', '1259', 0.36885163),\n",
       " ('25', '231', 0.36776513),\n",
       " ('25', '1580', 0.35882252),\n",
       " ('25', '1196', 0.35316643),\n",
       " ('25', '1208', 0.34781978),\n",
       " ('25', '597', 0.34514776),\n",
       " ('31', '79132', 0.5863189),\n",
       " ('31', '8360', 0.4894398),\n",
       " ('31', '68358', 0.47727883),\n",
       " ('31', '34405', 0.4651829),\n",
       " ('31', '6377', 0.45495123),\n",
       " ('31', '91542', 0.43585166),\n",
       " ('31', '59615', 0.41526023),\n",
       " ('31', '68954', 0.41303316),\n",
       " ('31', '31696', 0.4013761),\n",
       " ('31', '5349', 0.36646354),\n",
       " ('31', '52722', 0.36378717),\n",
       " ('31', '5882', 0.35039425),\n",
       " ('31', '95510', 0.34493938),\n",
       " ('31', '102445', 0.3447556),\n",
       " ('31', '53972', 0.34315693),\n",
       " ('31', '8644', 0.33564478),\n",
       " ('31', '3578', 0.32406363),\n",
       " ('31', '2628', 0.31763822),\n",
       " ('31', '111362', 0.317009),\n",
       " ('31', '7454', 0.3085951),\n",
       " ('35', '2959', 0.9024433),\n",
       " ('35', '5952', 0.8527687),\n",
       " ('35', '44191', 0.5641841),\n",
       " ('35', '33794', 0.54390883),\n",
       " ('35', '2762', 0.5033483),\n",
       " ('35', '8784', 0.50270015),\n",
       " ('35', '3996', 0.4966162),\n",
       " ('35', '3275', 0.4825517),\n",
       " ('35', '4963', 0.46988317),\n",
       " ('35', '4878', 0.46359125),\n",
       " ('35', '4306', 0.44101894),\n",
       " ('35', '6711', 0.4294351),\n",
       " ('35', '48516', 0.42710653),\n",
       " ('35', '608', 0.38465273),\n",
       " ('35', '5989', 0.38352773),\n",
       " ('35', '1206', 0.3768819),\n",
       " ('35', '8368', 0.37210703),\n",
       " ('35', '32', 0.37141654),\n",
       " ('35', '7147', 0.37038833),\n",
       " ('35', '53996', 0.3669556),\n",
       " ('43', '17', 0.4831239),\n",
       " ('43', '1196', 0.4421843),\n",
       " ('43', '4973', 0.39465567),\n",
       " ('43', '1197', 0.38338667),\n",
       " ('43', '1210', 0.35860655),\n",
       " ('43', '4963', 0.3574301),\n",
       " ('43', '7153', 0.3378995),\n",
       " ('43', '2762', 0.33704463),\n",
       " ('43', '2858', 0.3231953),\n",
       " ('43', '8360', 0.31476864),\n",
       " ('43', '4896', 0.3096026),\n",
       " ('43', '40629', 0.29781616),\n",
       " ('43', '3996', 0.28424174),\n",
       " ('43', '4993', 0.28124705),\n",
       " ('43', '4226', 0.27495053),\n",
       " ('43', '4995', 0.27458832),\n",
       " ('43', '480', 0.273587),\n",
       " ('43', '8961', 0.255933),\n",
       " ('43', '110', 0.2527018),\n",
       " ('43', '457', 0.2521501),\n",
       " ('50', '4993', 0.78964823),\n",
       " ('50', '527', 0.46057987),\n",
       " ('50', '6377', 0.42612553),\n",
       " ('50', '4226', 0.42247292),\n",
       " ('50', '293', 0.40436572),\n",
       " ('50', '50', 0.37934336),\n",
       " ('50', '1240', 0.3761954),\n",
       " ('50', '750', 0.36910912),\n",
       " ('50', '1089', 0.3670543),\n",
       " ('50', '7090', 0.35040745),\n",
       " ('50', '215', 0.34526533),\n",
       " ('50', '1258', 0.34439957),\n",
       " ('50', '1968', 0.33228323),\n",
       " ('50', '1', 0.324425),\n",
       " ('50', '1961', 0.32382253),\n",
       " ('50', '1682', 0.31822452),\n",
       " ('50', '32587', 0.31805855),\n",
       " ('50', '858', 0.30771694),\n",
       " ('50', '3897', 0.30765155),\n",
       " ('50', '1653', 0.3063685),\n",
       " ('58', '1246', 0.6961262),\n",
       " ('58', '1079', 0.6010736),\n",
       " ('58', '4995', 0.5668468),\n",
       " ('58', '25', 0.5576777),\n",
       " ('58', '1197', 0.52243745),\n",
       " ('58', '608', 0.5202248),\n",
       " ('58', '1610', 0.517417),\n",
       " ('58', '5669', 0.5173558),\n",
       " ('58', '2571', 0.51668096),\n",
       " ('58', '3911', 0.5023673),\n",
       " ('58', '1183', 0.49540633),\n",
       " ('58', '3160', 0.49332067),\n",
       " ('58', '778', 0.49001592),\n",
       " ('58', '1304', 0.4870362),\n",
       " ('58', '1500', 0.48416612),\n",
       " ('58', '4361', 0.4712393),\n",
       " ('58', '2324', 0.4674553),\n",
       " ('58', '50', 0.4665821),\n",
       " ('58', '1090', 0.462319),\n",
       " ('58', '1674', 0.46222243),\n",
       " ('60', '2571', 0.48031017),\n",
       " ('60', '1223', 0.44971326),\n",
       " ('60', '6539', 0.3551074),\n",
       " ('60', '4226', 0.31092566),\n",
       " ('60', '58559', 0.29817554),\n",
       " ('60', '4973', 0.2866047),\n",
       " ('60', '38038', 0.23885894),\n",
       " ('60', '30749', 0.23055175),\n",
       " ('60', '53125', 0.22265087),\n",
       " ('60', '858', 0.21091282),\n",
       " ('60', '1196', 0.20533285),\n",
       " ('60', '356', 0.20492347),\n",
       " ('60', '1203', 0.20358737),\n",
       " ('60', '2329', 0.20294349),\n",
       " ('60', '1089', 0.19956456),\n",
       " ('60', '50', 0.19582017),\n",
       " ('60', '4878', 0.19270556),\n",
       " ('60', '5618', 0.18840829),\n",
       " ('60', '1198', 0.18440711),\n",
       " ('60', '44191', 0.17396447),\n",
       " ('61', '4979', 0.57381225),\n",
       " ('61', '2959', 0.55985796),\n",
       " ('61', '32587', 0.45570585),\n",
       " ('61', '56367', 0.44959325),\n",
       " ('61', '44195', 0.43490773),\n",
       " ('61', '8636', 0.40464422),\n",
       " ('61', '2918', 0.40426853),\n",
       " ('61', '1884', 0.3915977),\n",
       " ('61', '1968', 0.3755674),\n",
       " ('61', '595', 0.34697154),\n",
       " ('61', '2571', 0.34463757),\n",
       " ('61', '30810', 0.34033155),\n",
       " ('61', '1704', 0.32816577),\n",
       " ('61', '58559', 0.32458413),\n",
       " ('61', '608', 0.32273182),\n",
       " ('61', '51662', 0.3021625),\n",
       " ('61', '6377', 0.2927689),\n",
       " ('61', '8376', 0.29181504),\n",
       " ('61', '6711', 0.2818742),\n",
       " ('61', '356', 0.27906328),\n",
       " ('65', '2571', 0.43357265),\n",
       " ('65', '58559', 0.3829544),\n",
       " ('65', '68954', 0.37046966),\n",
       " ('65', '2858', 0.3593847),\n",
       " ('65', '7323', 0.3265468),\n",
       " ('65', '745', 0.31076896),\n",
       " ('65', '4878', 0.29545364),\n",
       " ('65', '68157', 0.29446462),\n",
       " ('65', '32', 0.29028198),\n",
       " ('65', '6016', 0.2773746),\n",
       " ('65', '4235', 0.27107584),\n",
       " ('65', '5878', 0.25931057),\n",
       " ('65', '2762', 0.25909615),\n",
       " ('65', '48774', 0.25219467),\n",
       " ('65', '56367', 0.2371097),\n",
       " ('65', '3949', 0.2247816),\n",
       " ('65', '30749', 0.22477391),\n",
       " ('65', '4995', 0.21830368),\n",
       " ('65', '48780', 0.21801065),\n",
       " ('65', '2329', 0.21750224),\n",
       " ('72', '2959', 0.4035518),\n",
       " ('72', '1270', 0.39147726),\n",
       " ('72', '589', 0.3755843),\n",
       " ('72', '318', 0.37505817),\n",
       " ('72', '1080', 0.36756283),\n",
       " ('72', '2762', 0.36746308),\n",
       " ('72', '1193', 0.36426246),\n",
       " ('72', '778', 0.35815293),\n",
       " ('72', '50', 0.35619965),\n",
       " ('72', '1527', 0.33126256),\n",
       " ('72', '1258', 0.32388094),\n",
       " ('72', '750', 0.31764624),\n",
       " ('72', '344', 0.3106202),\n",
       " ('72', '608', 0.30525255),\n",
       " ('72', '7361', 0.3047902),\n",
       " ('72', '2028', 0.29566655),\n",
       " ('72', '1246', 0.2951369),\n",
       " ('72', '1089', 0.28547347),\n",
       " ('72', '1923', 0.28337595),\n",
       " ('72', '527', 0.2812661),\n",
       " ('77', '4993', 0.5973887),\n",
       " ('77', '2019', 0.5446408),\n",
       " ('77', '6874', 0.46025264),\n",
       " ('77', '589', 0.44201645),\n",
       " ('77', '1196', 0.38954777),\n",
       " ('77', '1222', 0.3533754),\n",
       " ('77', '1199', 0.3281592),\n",
       " ('77', '1219', 0.3226576),\n",
       " ('77', '593', 0.31661177),\n",
       " ('77', '1210', 0.3016442),\n",
       " ('77', '1193', 0.29680243),\n",
       " ('77', '1261', 0.29109246),\n",
       " ('77', '1653', 0.28321758),\n",
       " ('77', '1127', 0.26141763),\n",
       " ('77', '1215', 0.2543644),\n",
       " ('77', '858', 0.25274265),\n",
       " ('77', '551', 0.24958012),\n",
       " ('77', '1374', 0.24309024),\n",
       " ('77', '968', 0.23815085),\n",
       " ('77', '3949', 0.23790292),\n",
       " ('82', '1089', 0.5872951),\n",
       " ('82', '2028', 0.5381273),\n",
       " ('82', '68157', 0.52073216),\n",
       " ('82', '293', 0.5061482),\n",
       " ('82', '32587', 0.48144042),\n",
       " ('82', '4878', 0.44800198),\n",
       " ('82', '64839', 0.40916193),\n",
       " ('82', '8636', 0.40489498),\n",
       " ('82', '6377', 0.4046664),\n",
       " ('82', '46578', 0.39610517),\n",
       " ('82', '55118', 0.3957926),\n",
       " ('82', '5956', 0.39268193),\n",
       " ('82', '7361', 0.39040112),\n",
       " ('82', '1221', 0.38975036),\n",
       " ('82', '50872', 0.38306144),\n",
       " ('82', '31410', 0.3701844),\n",
       " ('82', '527', 0.36958206),\n",
       " ('82', '2571', 0.3657924),\n",
       " ('82', '858', 0.36469835),\n",
       " ('82', '55247', 0.35803458),\n",
       " ('85', '79132', 0.3897858),\n",
       " ('85', '68954', 0.3491995),\n",
       " ('85', '594', 0.3051455),\n",
       " ('85', '2018', 0.30436787),\n",
       " ('85', '81845', 0.29679283),\n",
       " ('85', '81834', 0.29361373),\n",
       " ('85', '91529', 0.2909434),\n",
       " ('85', '60069', 0.28200376),\n",
       " ('85', '2096', 0.27623546),\n",
       " ('85', '1032', 0.26378453),\n",
       " ('85', '951', 0.2543053),\n",
       " ('85', '908', 0.23913603),\n",
       " ('85', '6807', 0.23462394),\n",
       " ('85', '54286', 0.23049715),\n",
       " ('85', '915', 0.22882928),\n",
       " ('85', '595', 0.2261436),\n",
       " ('85', '1269', 0.22376178),\n",
       " ('85', '953', 0.21821198),\n",
       " ('85', '954', 0.21786773),\n",
       " ('85', '898', 0.21406202),\n",
       " ('90', '588', 0.6664197),\n",
       " ('90', '4896', 0.64939505),\n",
       " ('90', '110', 0.6106356),\n",
       " ('90', '1270', 0.5742445),\n",
       " ('90', '5349', 0.56191194),\n",
       " ('90', '1721', 0.5335506),\n",
       " ('90', '780', 0.5192917),\n",
       " ('90', '1097', 0.5127171),\n",
       " ('90', '1198', 0.45441544),\n",
       " ('90', '648', 0.43840346),\n",
       " ('90', '1073', 0.42904463),\n",
       " ('90', '2959', 0.41328585),\n",
       " ('90', '527', 0.402757),\n",
       " ('90', '231', 0.39922702),\n",
       " ('90', '2011', 0.38825342),\n",
       " ('90', '589', 0.38425547),\n",
       " ('90', '457', 0.38299823),\n",
       " ('90', '2571', 0.37229496),\n",
       " ('90', '2628', 0.3649797),\n",
       " ('90', '32587', 0.36049572),\n",
       " ('91', '457', 0.4194036),\n",
       " ('91', '1784', 0.40674344),\n",
       " ('91', '8665', 0.40391874),\n",
       " ('91', '4308', 0.39969715),\n",
       " ('91', '4973', 0.38710937),\n",
       " ('91', '4896', 0.37042668),\n",
       " ('91', '1393', 0.36818063),\n",
       " ('91', '1923', 0.3626235),\n",
       " ('91', '5989', 0.36247647),\n",
       " ('91', '8970', 0.35639152),\n",
       " ('91', '597', 0.3491864),\n",
       " ('91', '1246', 0.34364977),\n",
       " ('91', '2542', 0.343129),\n",
       " ('91', '1704', 0.33890143),\n",
       " ('91', '3897', 0.33542958),\n",
       " ('91', '3408', 0.33383137),\n",
       " ('91', '39', 0.33183736),\n",
       " ('91', '2174', 0.3185622),\n",
       " ('91', '2324', 0.31416178),\n",
       " ('91', '1', 0.30326423),\n",
       " ('96', '8665', 0.8835984),\n",
       " ('96', '56367', 0.77959496),\n",
       " ('96', '63082', 0.71460205),\n",
       " ('96', '68157', 0.7143706),\n",
       " ('96', '78499', 0.71336645),\n",
       " ('96', '110', 0.67201126),\n",
       " ('96', '2858', 0.64917594),\n",
       " ('96', '87232', 0.5818471),\n",
       " ('96', '6502', 0.54048663),\n",
       " ('96', '1527', 0.52299017),\n",
       " ('96', '91542', 0.48471716),\n",
       " ('96', '66097', 0.4843098),\n",
       " ('96', '98809', 0.47668368),\n",
       " ('96', '4896', 0.46619096),\n",
       " ('96', '76251', 0.4639152),\n",
       " ('96', '5816', 0.45604706),\n",
       " ('96', '102445', 0.45340657),\n",
       " ('96', '50', 0.44650516),\n",
       " ('96', '1580', 0.441269),\n",
       " ('96', '5349', 0.44064665),\n",
       " ('98', '260', 0.4932425),\n",
       " ('98', '2959', 0.48059186),\n",
       " ('98', '318', 0.40995163),\n",
       " ('98', '78499', 0.38975352),\n",
       " ('98', '4993', 0.3783709),\n",
       " ('98', '70286', 0.3639612),\n",
       " ('98', '4878', 0.3256644),\n",
       " ('98', '593', 0.3218695),\n",
       " ('98', '2858', 0.30393293),\n",
       " ('98', '74458', 0.30361795),\n",
       " ('98', '68358', 0.30309492),\n",
       " ('98', '3000', 0.28757057),\n",
       " ('98', '59315', 0.2782852),\n",
       " ('98', '7153', 0.2778479),\n",
       " ('98', '63082', 0.2732193),\n",
       " ('98', '110', 0.27166513),\n",
       " ('98', '5618', 0.26912716),\n",
       " ('98', '1682', 0.2674125),\n",
       " ('98', '480', 0.26432055),\n",
       " ('98', '1214', 0.261217),\n",
       " ('99', '4226', 0.6087976),\n",
       " ('99', '1089', 0.5654921),\n",
       " ('99', '2571', 0.44639468),\n",
       " ('99', '50', 0.39942676),\n",
       " ('99', '6807', 0.38696086),\n",
       " ('99', '1193', 0.32336104),\n",
       " ('99', '48516', 0.32334346),\n",
       " ('99', '1196', 0.31926388),\n",
       " ('99', '1258', 0.31023732),\n",
       " ('99', '293', 0.29875836),\n",
       " ('99', '6874', 0.29663748),\n",
       " ('99', '48394', 0.29511428),\n",
       " ('99', '1732', 0.27897435),\n",
       " ('99', '4973', 0.27712038),\n",
       " ('99', '6016', 0.27677178),\n",
       " ('99', '33794', 0.26590404),\n",
       " ('99', '32', 0.25354558),\n",
       " ('99', '858', 0.24044839),\n",
       " ('99', '1210', 0.22646666),\n",
       " ('99', '2997', 0.22103529),\n",
       " ('102', '50', 0.56254935),\n",
       " ('102', '7361', 0.5240479),\n",
       " ('102', '7438', 0.48646688),\n",
       " ('102', '356', 0.48004562),\n",
       " ('102', '5952', 0.46707597),\n",
       " ('102', '2858', 0.4028383),\n",
       " ('102', '7153', 0.36635643),\n",
       " ('102', '1197', 0.35570216),\n",
       " ('102', '58559', 0.3493808),\n",
       " ('102', '593', 0.34205857),\n",
       " ('102', '589', 0.336225),\n",
       " ('102', '527', 0.31996402),\n",
       " ('102', '1198', 0.3075652),\n",
       " ('102', '1704', 0.30719575),\n",
       " ('102', '1210', 0.29627705),\n",
       " ('102', '912', 0.29594642),\n",
       " ('102', '1193', 0.29552686),\n",
       " ('102', '1527', 0.29419044),\n",
       " ('102', '2918', 0.2681061),\n",
       " ('102', '1035', 0.26300246),\n",
       " ('116', '1240', 0.62488735),\n",
       " ('116', '4226', 0.5211807),\n",
       " ('116', '2762', 0.46981898),\n",
       " ('116', '593', 0.4627781),\n",
       " ('116', '2502', 0.4546576),\n",
       " ('116', '1221', 0.4253916),\n",
       " ('116', '5903', 0.41924286),\n",
       " ('116', '1197', 0.41415197),\n",
       " ('116', '6', 0.41279945),\n",
       " ('116', '4776', 0.4088884),\n",
       " ('116', '2716', 0.40070304),\n",
       " ('116', '231', 0.38399982),\n",
       " ('116', '8636', 0.36387023),\n",
       " ('116', '1200', 0.36047748),\n",
       " ('116', '2058', 0.35947475),\n",
       " ('116', '1', 0.35768783),\n",
       " ('116', '5956', 0.35293105),\n",
       " ('116', '44191', 0.3495438),\n",
       " ('116', '253', 0.34249339),\n",
       " ('116', '1517', 0.34166992),\n",
       " ('121', '2628', 0.44800225),\n",
       " ('121', '34162', 0.41849354),\n",
       " ('121', '1136', 0.31855652),\n",
       " ('121', '59315', 0.3088128),\n",
       " ('121', '63131', 0.30824935),\n",
       " ('121', '67087', 0.2734141),\n",
       " ('121', '8807', 0.26249123),\n",
       " ('121', '48385', 0.25673035),\n",
       " ('121', '1213', 0.25005245),\n",
       " ('121', '4993', 0.24837275),\n",
       " ('121', '48516', 0.246194),\n",
       " ('121', '44191', 0.24540222),\n",
       " ('121', '2571', 0.24447447),\n",
       " ('121', '51662', 0.23890245),\n",
       " ('121', '61132', 0.23386425),\n",
       " ('121', '6936', 0.22726569),\n",
       " ('121', '4306', 0.22099265),\n",
       " ('121', '318', 0.22087765),\n",
       " ('121', '8528', 0.21736775),\n",
       " ('121', '32587', 0.20964542),\n",
       " ('124', '733', 0.742043),\n",
       " ('124', '527', 0.59756017),\n",
       " ('124', '6539', 0.5749671),\n",
       " ('124', '1784', 0.5689041),\n",
       " ('124', '377', 0.54752827),\n",
       " ('124', '2028', 0.53990245),\n",
       " ('124', '2000', 0.53024954),\n",
       " ('124', '2396', 0.5018061),\n",
       " ('124', '592', 0.49787635),\n",
       " ('124', '260', 0.49754506),\n",
       " ('124', '2716', 0.48495433),\n",
       " ('124', '1200', 0.48160505),\n",
       " ('124', '3147', 0.4735746),\n",
       " ('124', '480', 0.4546704),\n",
       " ('124', '2987', 0.4424486),\n",
       " ('124', '1625', 0.43787366),\n",
       " ('124', '2355', 0.4358184),\n",
       " ('124', '4022', 0.42708227),\n",
       " ('124', '8665', 0.42519826),\n",
       " ('124', '3948', 0.41873804),\n",
       " ('129', '4886', 0.5663002),\n",
       " ('129', '5816', 0.4134724),\n",
       " ('129', '7153', 0.36279476),\n",
       " ('129', '60069', 0.35907397),\n",
       " ('129', '8368', 0.35308987),\n",
       " ('129', '778', 0.3131741),\n",
       " ('129', '48385', 0.30619127),\n",
       " ('129', '8360', 0.29642752),\n",
       " ('129', '63082', 0.2887623),\n",
       " ('129', '71535', 0.28260264),\n",
       " ('129', '356', 0.2755341),\n",
       " ('129', '8874', 0.2748764),\n",
       " ('129', '6711', 0.2705748),\n",
       " ('129', '588', 0.2686712),\n",
       " ('129', '76251', 0.2684132),\n",
       " ('129', '34162', 0.2673252),\n",
       " ('129', '68157', 0.26606858),\n",
       " ('129', '72011', 0.26500002),\n",
       " ('129', '500', 0.26444557),\n",
       " ('129', '5952', 0.26064488),\n",
       " ('132', '47', 0.5976072),\n",
       " ('132', '2571', 0.59463483),\n",
       " ('132', '7153', 0.5878079),\n",
       " ('132', '2174', 0.57137996),\n",
       " ('132', '1221', 0.5408862),\n",
       " ('132', '589', 0.52872163),\n",
       " ('132', '2692', 0.5026313),\n",
       " ('132', '750', 0.501708),\n",
       " ('132', '2918', 0.48339972),\n",
       " ('132', '1265', 0.48278224),\n",
       " ('132', '1673', 0.4780349),\n",
       " ('132', '1208', 0.46332812),\n",
       " ('132', '1', 0.45646518),\n",
       " ('132', '6539', 0.45389715),\n",
       " ('132', '1961', 0.45251283),\n",
       " ('132', '8784', 0.44140694),\n",
       " ('132', '919', 0.4213543),\n",
       " ('132', '923', 0.41331092),\n",
       " ('132', '235', 0.41222507),\n",
       " ('132', '1213', 0.4083096),\n",
       " ('133', '46578', 0.82106256),\n",
       " ('133', '74458', 0.6852966),\n",
       " ('133', '6016', 0.6108005),\n",
       " ('133', '81845', 0.5904379),\n",
       " ('133', '48394', 0.5560367),\n",
       " ('133', '4306', 0.5301968),\n",
       " ('133', '858', 0.51417065),\n",
       " ('133', '8874', 0.508538),\n",
       " ('133', '1206', 0.50761163),\n",
       " ('133', '63082', 0.49755454),\n",
       " ('133', '4995', 0.49258786),\n",
       " ('133', '608', 0.48135918),\n",
       " ('133', '1732', 0.46416304),\n",
       " ('133', '70286', 0.45476958),\n",
       " ('133', '56782', 0.45181987),\n",
       " ('133', '364', 0.42451426),\n",
       " ('133', '72998', 0.40826246),\n",
       " ('133', '82459', 0.4043005),\n",
       " ('133', '5618', 0.40190873),\n",
       " ('133', '1246', 0.40091324),\n",
       " ('135', '588', 0.50603604),\n",
       " ('135', '8360', 0.47548732),\n",
       " ('135', '364', 0.45895028),\n",
       " ('135', '1148', 0.45170072),\n",
       " ('135', '1270', 0.42113003),\n",
       " ('135', '5418', 0.40472943),\n",
       " ('135', '260', 0.4002158),\n",
       " ('135', '1196', 0.3998654),\n",
       " ('135', '594', 0.3856929),\n",
       " ('135', '1035', 0.37738776),\n",
       " ('135', '4963', 0.35162613),\n",
       " ('135', '2078', 0.34779182),\n",
       " ('135', '2028', 0.3415503),\n",
       " ('135', '1704', 0.32253656),\n",
       " ('135', '1291', 0.31427172),\n",
       " ('135', '1242', 0.30407116),\n",
       " ('135', '5445', 0.3021945),\n",
       " ('135', '7143', 0.29977697),\n",
       " ('135', '480', 0.29911247),\n",
       " ('135', '1223', 0.2959287),\n",
       " ('136', '4896', 0.77172536),\n",
       " ('136', '7153', 0.51129776),\n",
       " ('136', '5952', 0.49613237),\n",
       " ('136', '86345', 0.47542778),\n",
       " ('136', '364', 0.45788935),\n",
       " ('136', '2571', 0.41382688),\n",
       " ('136', '6333', 0.3964591),\n",
       " ('136', '595', 0.38723668),\n",
       " ('136', '98809', 0.36352277),\n",
       " ('136', '72998', 0.35300043),\n",
       " ('136', '77561', 0.34670773),\n",
       " ('136', '88140', 0.3421442),\n",
       " ('136', '8636', 0.34145778),\n",
       " ('136', '3578', 0.3391359),\n",
       " ('136', '76093', 0.33190313),\n",
       " ('136', '91542', 0.3308634),\n",
       " ('136', '85414', 0.33074927),\n",
       " ('136', '33794', 0.32332706),\n",
       " ('136', '106489', 0.31131268),\n",
       " ('136', '76251', 0.29659072),\n",
       " ('147', '1197', 0.7271818),\n",
       " ('147', '589', 0.5617125),\n",
       " ('147', '1080', 0.5526635),\n",
       " ('147', '750', 0.53399354),\n",
       " ('147', '527', 0.5129815),\n",
       " ('147', '1258', 0.49891),\n",
       " ('147', '2918', 0.4882663),\n",
       " ('147', '1682', 0.47773913),\n",
       " ('147', '6711', 0.4762115),\n",
       " ('147', '778', 0.47581965),\n",
       " ('147', '1206', 0.4648602),\n",
       " ('147', '4886', 0.4611092),\n",
       " ('147', '2858', 0.4540488),\n",
       " ('147', '8874', 0.450047),\n",
       " ('147', '1923', 0.44480824),\n",
       " ('147', '1617', 0.43864036),\n",
       " ('147', '1210', 0.43228677),\n",
       " ('147', '1213', 0.43227822),\n",
       " ('147', '356', 0.42497376),\n",
       " ('147', '1079', 0.4226632),\n",
       " ('152', '356', 0.8351705),\n",
       " ('152', '2683', 0.64036775),\n",
       " ('152', '1', 0.5997493),\n",
       " ('152', '2571', 0.534251),\n",
       " ('152', '1682', 0.5242989),\n",
       " ('152', '5418', 0.51483655),\n",
       " ('152', '32587', 0.49049783),\n",
       " ('152', '3793', 0.4883166),\n",
       " ('152', '110', 0.48745772),\n",
       " ('152', '597', 0.47957173),\n",
       " ('152', '8961', 0.47737533),\n",
       " ('152', '595', 0.4555827),\n",
       " ('152', '5952', 0.43613404),\n",
       " ('152', '1265', 0.41106972),\n",
       " ('152', '1196', 0.40898797),\n",
       " ('152', '7153', 0.4024065),\n",
       " ('152', '3147', 0.39846143),\n",
       " ('152', '4022', 0.38749978),\n",
       " ('152', '45722', 0.3868657),\n",
       " ('152', '586', 0.38347477),\n",
       " ('154', '2997', 0.72553205),\n",
       " ('154', '1617', 0.60223913),\n",
       " ('154', '8949', 0.5892904),\n",
       " ('154', '778', 0.5821546),\n",
       " ('154', '3996', 0.5758013),\n",
       " ('154', '4973', 0.5634077),\n",
       " ('154', '46578', 0.5188172),\n",
       " ('154', '318', 0.5143304),\n",
       " ('154', '8665', 0.5075003),\n",
       " ('154', '7090', 0.48648223),\n",
       " ('154', '3481', 0.47494665),\n",
       " ('154', '293', 0.47037598),\n",
       " ('154', '1673', 0.46507505),\n",
       " ('154', '593', 0.4428908),\n",
       " ('154', '16', 0.44113383),\n",
       " ('154', '30749', 0.43994108),\n",
       " ('154', '4776', 0.4313393),\n",
       " ('154', '6708', 0.39811036),\n",
       " ('154', '3948', 0.394554),\n",
       " ('154', '1247', 0.39243823),\n",
       " ('155', '2959', 0.4969033),\n",
       " ('155', '318', 0.43608987),\n",
       " ('155', '4011', 0.3430729),\n",
       " ('155', '2997', 0.33877003),\n",
       " ('155', '593', 0.30691966),\n",
       " ('155', '1089', 0.30620933),\n",
       " ('155', '6377', 0.2998244),\n",
       " ('155', '47', 0.2877824),\n",
       " ('155', '541', 0.28301534),\n",
       " ('155', '1270', 0.28043222),\n",
       " ('155', '1136', 0.26912236),\n",
       " ('155', '46578', 0.26599833),\n",
       " ('155', '2692', 0.25592417),\n",
       " ('155', '2329', 0.25149357),\n",
       " ('155', '1197', 0.24514998),\n",
       " ('155', '608', 0.24182178),\n",
       " ('155', '5618', 0.23844293),\n",
       " ('155', '48780', 0.2349134),\n",
       " ('155', '1199', 0.22245131),\n",
       " ('155', '8874', 0.22108795),\n",
       " ('162', '5952', 0.8983437),\n",
       " ('162', '2959', 0.57357776),\n",
       " ('162', '3000', 0.5120609),\n",
       " ('162', '7361', 0.5014234),\n",
       " ('162', '5349', 0.48768872),\n",
       " ('162', '1198', 0.48413882),\n",
       " ('162', '32587', 0.48071268),\n",
       " ('162', '34405', 0.4454147),\n",
       " ('162', '44191', 0.44272536),\n",
       " ('162', '6874', 0.43162856),\n",
       " ('162', '68954', 0.41449213),\n",
       " ('162', '3578', 0.40098011),\n",
       " ('162', '6539', 0.39628065),\n",
       " ('162', '778', 0.389474),\n",
       " ('162', '48394', 0.38939422),\n",
       " ('162', '296', 0.38605735),\n",
       " ('162', '79132', 0.3793979),\n",
       " ('162', '1221', 0.377442),\n",
       " ('162', '4011', 0.37528223),\n",
       " ('162', '51255', 0.37347725),\n",
       " ('163', '48516', 0.5409925),\n",
       " ('163', '296', 0.50132924),\n",
       " ('163', '2571', 0.48346096),\n",
       " ('163', '49272', 0.4179676),\n",
       " ('163', '56367', 0.41270307),\n",
       " ('163', '50', 0.40923256),\n",
       " ('163', '44191', 0.39430186),\n",
       " ('163', '7438', 0.37366393),\n",
       " ('163', '51662', 0.33989298),\n",
       " ('163', '593', 0.32961023),\n",
       " ('163', '5418', 0.31003293),\n",
       " ('163', '2329', 0.29650053),\n",
       " ('163', '6377', 0.28512534),\n",
       " ('163', '1221', 0.28274164),\n",
       " ('163', '55765', 0.27686864),\n",
       " ('163', '4878', 0.27092838),\n",
       " ('163', '3578', 0.27007577),\n",
       " ('163', '6934', 0.26712528),\n",
       " ('163', '44199', 0.2634964),\n",
       " ('163', '48774', 0.26101574),\n",
       " ('168', '2997', 0.8458853),\n",
       " ('168', '50', 0.6170207),\n",
       " ('168', '1', 0.5943082),\n",
       " ('168', '3949', 0.527014),\n",
       " ('168', '2683', 0.49226716),\n",
       " ('168', '4973', 0.4760898),\n",
       " ('168', '2542', 0.45368204),\n",
       " ('168', '318', 0.4425575),\n",
       " ('168', '1199', 0.44125217),\n",
       " ('168', '4027', 0.4087091),\n",
       " ('168', '2700', 0.40508378),\n",
       " ('168', '32587', 0.39829266),\n",
       " ('168', '541', 0.39401034),\n",
       " ('168', '923', 0.359933),\n",
       " ('168', '1213', 0.356406),\n",
       " ('168', '2076', 0.3545528),\n",
       " ('168', '2174', 0.35371336),\n",
       " ('168', '293', 0.3496303),\n",
       " ('168', '2918', 0.3305739),\n",
       " ('168', '6711', 0.32599455),\n",
       " ('175', '480', 0.4465614),\n",
       " ('175', '1270', 0.4326072),\n",
       " ('175', '110', 0.38624597),\n",
       " ('175', '527', 0.35897714),\n",
       " ('175', '3578', 0.33875272),\n",
       " ('175', '1704', 0.33644342),\n",
       " ('175', '1221', 0.32819307),\n",
       " ('175', '1198', 0.32816583),\n",
       " ('175', '780', 0.32067308),\n",
       " ('175', '33794', 0.31821728),\n",
       " ('175', '8665', 0.31595722),\n",
       " ('175', '4226', 0.31005776),\n",
       " ('175', '47', 0.30875158),\n",
       " ('175', '5989', 0.29541054),\n",
       " ('175', '377', 0.2950948),\n",
       " ('175', '2959', 0.2947668),\n",
       " ('175', '590', 0.28413013),\n",
       " ('175', '5445', 0.2817365),\n",
       " ('175', '4993', 0.2701618),\n",
       " ('175', '1617', 0.2599032),\n",
       " ('182', '5418', 0.4736064),\n",
       " ('182', '59315', 0.3984858),\n",
       " ('182', '77561', 0.3050184),\n",
       " ('182', '89745', 0.26650402),\n",
       " ('182', '69122', 0.2486254),\n",
       " ('182', '79132', 0.23795006),\n",
       " ('182', '59369', 0.23781797),\n",
       " ('182', '51662', 0.23514189),\n",
       " ('182', '91542', 0.22744602),\n",
       " ('182', '76251', 0.21873137),\n",
       " ('182', '53519', 0.21832795),\n",
       " ('182', '52281', 0.18519552),\n",
       " ('182', '85414', 0.16344164),\n",
       " ('182', '68358', 0.16006896),\n",
       " ('182', '60040', 0.15605615),\n",
       " ('182', '27831', 0.1559428),\n",
       " ('182', '44665', 0.15585695),\n",
       " ('182', '55765', 0.15375121),\n",
       " ('182', '84152', 0.15036802),\n",
       " ('182', '44191', 0.150254),\n",
       " ('189', '5816', 0.72442645),\n",
       " ('189', '1210', 0.61312574),\n",
       " ('189', '593', 0.5606601),\n",
       " ('189', '5952', 0.48359707),\n",
       " ('189', '4306', 0.46010208),\n",
       " ('189', '1517', 0.4542726),\n",
       " ('189', '344', 0.44707868),\n",
       " ('189', '588', 0.42952642),\n",
       " ('189', '595', 0.42544875),\n",
       " ('189', '2571', 0.42398825),\n",
       " ('189', '1198', 0.41326526),\n",
       " ('189', '7153', 0.40442887),\n",
       " ('189', '1580', 0.4009822),\n",
       " ('189', '3052', 0.39166188),\n",
       " ('189', '2762', 0.3916376),\n",
       " ('189', '6539', 0.38932377),\n",
       " ('189', '253', 0.38616052),\n",
       " ('189', '3578', 0.3787662),\n",
       " ('189', '6377', 0.37122768),\n",
       " ('189', '551', 0.36455092),\n",
       " ('190', '4226', 0.37932673),\n",
       " ('190', '33794', 0.31053668),\n",
       " ('190', '2762', 0.29205596),\n",
       " ('190', '1704', 0.28077587),\n",
       " ('190', '356', 0.2755885),\n",
       " ('190', '8784', 0.26792994),\n",
       " ('190', '3949', 0.26585817),\n",
       " ('190', '7147', 0.26550505),\n",
       " ('190', '50', 0.25674057),\n",
       " ('190', '1265', 0.2558789),\n",
       " ('190', '296', 0.24783932),\n",
       " ('190', '5952', 0.24761829),\n",
       " ('190', '60069', 0.24214606),\n",
       " ('190', '63082', 0.2376951),\n",
       " ('190', '59315', 0.22911501),\n",
       " ('190', '4014', 0.21120374),\n",
       " ('190', '2716', 0.21048726),\n",
       " ('190', '6377', 0.20857024),\n",
       " ('190', '44191', 0.20600964),\n",
       " ('190', '2918', 0.20488031),\n",
       " ('201', '1221', 0.39009613),\n",
       " ('201', '6016', 0.38301408),\n",
       " ('201', '4973', 0.36424395),\n",
       " ('201', '924', 0.35594562),\n",
       " ('201', '903', 0.33464187),\n",
       " ('201', '912', 0.3102027),\n",
       " ('201', '1354', 0.29969218),\n",
       " ('201', '7099', 0.29372752),\n",
       " ('201', '7323', 0.288455),\n",
       " ('201', '750', 0.28528348),\n",
       " ('201', '5878', 0.2834838),\n",
       " ('201', '27266', 0.27097604),\n",
       " ('201', '2858', 0.26912853),\n",
       " ('201', '1921', 0.26584587),\n",
       " ('201', '34437', 0.26439542),\n",
       " ('201', '6711', 0.24871203),\n",
       " ('201', '1251', 0.2289117),\n",
       " ('201', '714', 0.22688381),\n",
       " ('201', '5971', 0.2263617),\n",
       " ('201', '31658', 0.21563822),\n",
       " ('204', '318', 0.48196283),\n",
       " ('204', '2571', 0.44541755),\n",
       " ('204', '593', 0.44204882),\n",
       " ('204', '1291', 0.4363861),\n",
       " ('204', '364', 0.43026444),\n",
       " ('204', '2329', 0.3643192),\n",
       " ('204', '1270', 0.34943455),\n",
       " ('204', '68954', 0.34920773),\n",
       " ('204', '4973', 0.34819752),\n",
       " ('204', '2858', 0.33406687),\n",
       " ('204', '2716', 0.3314759),\n",
       " ('204', '4993', 0.3236809),\n",
       " ('204', '2502', 0.32162344),\n",
       " ('204', '2762', 0.31604582),\n",
       " ('204', '592', 0.3027243),\n",
       " ('204', '6874', 0.2932723),\n",
       " ('204', '58559', 0.29273048),\n",
       " ('204', '2997', 0.28852293),\n",
       " ('204', '1527', 0.28575084),\n",
       " ('204', '778', 0.2812646),\n",
       " ('205', '4896', 0.63042974),\n",
       " ('205', '110', 0.53273964),\n",
       " ('205', '593', 0.52161527),\n",
       " ('205', '1704', 0.5066587),\n",
       " ('205', '318', 0.50279176),\n",
       " ('205', '2762', 0.49786526),\n",
       " ('205', '4226', 0.47809875),\n",
       " ('205', '1200', 0.42898172),\n",
       " ('205', '1580', 0.4213526),\n",
       " ('205', '2858', 0.41090563),\n",
       " ('205', '8360', 0.40248704),\n",
       " ('205', '1617', 0.37481672),\n",
       " ('205', '480', 0.3735445),\n",
       " ('205', '4886', 0.37209603),\n",
       " ('205', '260', 0.36932367),\n",
       " ('205', '6874', 0.35511243),\n",
       " ('205', '1265', 0.34273344),\n",
       " ('205', '2716', 0.33778566),\n",
       " ('205', '8961', 0.32940197),\n",
       " ('205', '457', 0.32302842),\n",
       " ('206', '5418', 0.5312507),\n",
       " ('206', '8368', 0.5220902),\n",
       " ('206', '3793', 0.46438617),\n",
       " ('206', '4025', 0.3925987),\n",
       " ('206', '33679', 0.39086413),\n",
       " ('206', '6539', 0.38910016),\n",
       " ('206', '8360', 0.35443145),\n",
       " ('206', '145', 0.34497195),\n",
       " ('206', '3996', 0.32807446),\n",
       " ('206', '39', 0.30657455),\n",
       " ('206', '3623', 0.30519116),\n",
       " ('206', '6942', 0.29898745),\n",
       " ('206', '4270', 0.2943168),\n",
       " ('206', '6155', 0.28502658),\n",
       " ('206', '457', 0.28491718),\n",
       " ('206', '3717', 0.28398672),\n",
       " ('206', '2000', 0.27140778),\n",
       " ('206', '2001', 0.27127603),\n",
       " ('206', '7293', 0.26794502),\n",
       " ('206', '5872', 0.26528165),\n",
       " ('208', '86882', 0.51569),\n",
       " ('208', '858', 0.48523587),\n",
       " ('208', '89492', 0.4801764),\n",
       " ('208', '39183', 0.4740537),\n",
       " ('208', '48780', 0.473767),\n",
       " ('208', '79132', 0.44430423),\n",
       " ('208', '81591', 0.44287512),\n",
       " ('208', '60766', 0.43752354),\n",
       " ('208', '215', 0.43684933),\n",
       " ('208', '296', 0.43143868),\n",
       " ('208', '64620', 0.4283288),\n",
       " ('208', '7566', 0.41081846),\n",
       " ('208', '34542', 0.4050113),\n",
       " ('208', '78574', 0.40173334),\n",
       " ('208', '2395', 0.39596868),\n",
       " ('208', '64614', 0.39232403),\n",
       " ('208', '1199', 0.38495934),\n",
       " ('208', '1203', 0.38087586),\n",
       " ('208', '51540', 0.37605968),\n",
       " ('208', '6711', 0.3701972),\n",
       " ('209', '150', 0.22668318),\n",
       " ('209', '104', 0.21023631),\n",
       " ('209', '78499', 0.20297481),\n",
       " ('209', '5669', 0.19849269),\n",
       " ('209', '47099', 0.19567),\n",
       " ('209', '33660', 0.1873558),\n",
       " ('209', '48516', 0.18259819),\n",
       " ('209', '4022', 0.18188837),\n",
       " ('209', '50', 0.17896117),\n",
       " ('209', '63082', 0.17665689),\n",
       " ('209', '110', 0.17507397),\n",
       " ('209', '68157', 0.17459914),\n",
       " ('209', '1270', 0.174277),\n",
       " ('209', '81562', 0.17255466),\n",
       " ('209', '74458', 0.1693509),\n",
       " ('209', '2571', 0.16574487),\n",
       " ('209', '4995', 0.16482988),\n",
       " ('209', '30707', 0.16220006),\n",
       " ('209', '527', 0.16212317),\n",
       " ('209', '64614', 0.16031922),\n",
       " ('211', '6874', 0.612299),\n",
       " ('211', '1', 0.5763517),\n",
       " ('211', '4963', 0.50547147),\n",
       " ('211', '110', 0.48945564),\n",
       " ('211', '480', 0.48055363),\n",
       " ('211', '47', 0.35134226),\n",
       " ('211', '1221', 0.3326013),\n",
       " ('211', '588', 0.31537995),\n",
       " ('211', '2683', 0.3026393),\n",
       " ('211', '1240', 0.2984452),\n",
       " ('211', '595', 0.2866084),\n",
       " ('211', '1198', 0.27367637),\n",
       " ('211', '1704', 0.2729019),\n",
       " ('211', '50', 0.27007768),\n",
       " ('211', '3147', 0.26598358),\n",
       " ('211', '32587', 0.25900352),\n",
       " ('211', '1961', 0.25286898),\n",
       " ('211', '5418', 0.24042952),\n",
       " ('211', '4973', 0.23913395),\n",
       " ('211', '3114', 0.230304),\n",
       " ('213', '1704', 0.43511322),\n",
       " ('213', '79132', 0.3834272),\n",
       " ('213', '6377', 0.38205865),\n",
       " ('213', '4306', 0.3660669),\n",
       " ('213', '1682', 0.34659407),\n",
       " ('213', '58559', 0.32073858),\n",
       " ('213', '97921', 0.31486037),\n",
       " ('213', '2028', 0.30965275),\n",
       " ('213', '8961', 0.30745628),\n",
       " ('213', '91529', 0.29553977),\n",
       " ('213', '3147', 0.29176444),\n",
       " ('213', '2762', 0.2860031),\n",
       " ('213', '68157', 0.28134763),\n",
       " ('213', '608', 0.26394942),\n",
       " ('213', '96079', 0.25897175),\n",
       " ('213', '1968', 0.2505008),\n",
       " ('213', '5418', 0.2459843),\n",
       " ('213', '78499', 0.23740172),\n",
       " ('213', '59315', 0.23621035),\n",
       " ('213', '79091', 0.21829619),\n",
       " ('215', '778', 0.5627674),\n",
       " ('215', '1197', 0.5601833),\n",
       " ('215', '750', 0.5320228),\n",
       " ('215', '318', 0.5202834),\n",
       " ('215', '1222', 0.4609792),\n",
       " ('215', '593', 0.4474061),\n",
       " ('215', '111', 0.44255883),\n",
       " ('215', '4027', 0.43892208),\n",
       " ('215', '35836', 0.4291636),\n",
       " ('215', '1617', 0.42722833),\n",
       " ('215', '1240', 0.42499354),\n",
       " ('215', '48516', 0.41703197),\n",
       " ('215', '50', 0.41617796),\n",
       " ('215', '1080', 0.4126924),\n",
       " ('215', '4011', 0.4095748),\n",
       " ('215', '32', 0.39592102),\n",
       " ('215', '2716', 0.3941877),\n",
       " ('215', '5445', 0.3941853),\n",
       " ('215', '5673', 0.38451016),\n",
       " ('215', '1653', 0.3583182),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 저장할 빈 리스트 초기화\n",
    "final_result = []\n",
    "\n",
    "# user_list, pred_list, score_list에 있는 값들을 함께 저장\n",
    "for user, item, score in zip(user_list, pred_list, score_list):\n",
    "    # user_id2token을 사용하여 변환된 사용자 ID를 얻고\n",
    "    original_user_seq = user_id2token[user]\n",
    "\n",
    "    # item_id2token을 사용하여 변환된 아이템 ID를 얻고 \n",
    "    original_item_seq = item_id2token[item]\n",
    "\n",
    "    # 사용자 ID, 아이템 ID, 예측 점수를 튜플로 저장\n",
    "    final_result.append((original_user_seq, original_item_seq, score))\n",
    "\n",
    "final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4886</td>\n",
       "      <td>0.826884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4370</td>\n",
       "      <td>0.754824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>8961</td>\n",
       "      <td>0.751770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>40815</td>\n",
       "      <td>0.699711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>0.548352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627195</th>\n",
       "      <td>138493</td>\n",
       "      <td>597</td>\n",
       "      <td>0.419247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627196</th>\n",
       "      <td>138493</td>\n",
       "      <td>589</td>\n",
       "      <td>0.418782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627197</th>\n",
       "      <td>138493</td>\n",
       "      <td>8961</td>\n",
       "      <td>0.415376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627198</th>\n",
       "      <td>138493</td>\n",
       "      <td>45517</td>\n",
       "      <td>0.407788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627199</th>\n",
       "      <td>138493</td>\n",
       "      <td>41569</td>\n",
       "      <td>0.402867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user   item     score\n",
       "0           11   4886  0.826884\n",
       "1           11   4370  0.754824\n",
       "2           11   8961  0.751770\n",
       "3           11  40815  0.699711\n",
       "4           11     47  0.548352\n",
       "...        ...    ...       ...\n",
       "627195  138493    597  0.419247\n",
       "627196  138493    589  0.418782\n",
       "627197  138493   8961  0.415376\n",
       "627198  138493  45517  0.407788\n",
       "627199  138493  41569  0.402867\n",
       "\n",
       "[627200 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 DataFrame으로 변환하고 CSV 파일로 저장\n",
    "final_dataframe = pd.DataFrame(final_result, columns=['user', 'item', 'score'])\n",
    "# final_dataframe.to_csv('./data/eval/recbole_ease_1.csv', index=False)\n",
    "final_dataframe.to_csv('./data/eval/score/score_ease_1.csv', index=False)\n",
    "final_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
